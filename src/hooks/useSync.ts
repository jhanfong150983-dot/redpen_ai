import { useState, useEffect, useCallback, useRef } from 'react'
import { db } from '@/lib/db'
import { useOnlineStatus } from './useOnlineStatus'
import { SYNC_EVENT_NAME, notifySyncComplete } from '@/lib/sync-events'
import { clearDeleteQueue, readDeleteQueue } from '@/lib/sync-delete-queue'
import type { Assignment, Classroom, Student, Submission } from '@/lib/db'
import { blobToBase64 as blobToDataUrl, compressImage } from '@/lib/imageCompression'
import { downloadImageFromSupabase } from '@/lib/supabase-download'
import { fixCorruptedBase64 } from '@/lib/utils'
import { isIndexedDbBlobError, shouldAvoidIndexedDbBlob } from '@/lib/blob-storage'
import { debugLog, infoLog } from '@/lib/logger'

interface SyncStatus {
  isSyncing: boolean
  lastSyncTime: number | null
  pendingCount: number
  error: string | null
}

interface UseSyncOptions {
  autoSync?: boolean
  syncInterval?: number // ä¿ç•™åƒæ•¸ä»¥ç›¸å®¹èˆŠå‘¼å«
}

const normalizeBase64Payload = (
  rawBase64: string,
  fallbackMimeType?: string
): { data: string; mimeType?: string; dataUrl: string } => {
  const fixed = fixCorruptedBase64(rawBase64.trim())
  if (fixed.startsWith('data:')) {
    const commaIndex = fixed.indexOf(',')
    if (commaIndex > -1) {
      const meta = fixed.slice(5, commaIndex)
      const mimeType = meta.split(';')[0] || fallbackMimeType
      return {
        data: fixed.slice(commaIndex + 1),
        mimeType,
        dataUrl: fixed
      }
    }
  }

  const mimeType = fallbackMimeType || 'image/jpeg'
  return {
    data: fixed,
    mimeType,
    dataUrl: `data:${mimeType};base64,${fixed}`
  }
}

const MAX_SUBMISSION_BASE64_LENGTH = 2_700_000
const HARD_MAX_SUBMISSION_BASE64_LENGTH = 1_600_000

const shrinkBase64Payload = async (
  dataUrl: string,
  fallbackMimeType: string | undefined,
  targetLength: number
) => {
  let normalized = normalizeBase64Payload(dataUrl, fallbackMimeType)
  if (normalized.data.length <= targetLength) {
    return { ...normalized, updated: false }
  }

  const strategies = [
    { maxWidth: 1400, quality: 0.75 },
    { maxWidth: 1200, quality: 0.7 },
    { maxWidth: 1024, quality: 0.65 },
    { maxWidth: 900, quality: 0.6 },
    { maxWidth: 800, quality: 0.55 }
  ]

  let currentDataUrl = normalized.dataUrl

  for (const strategy of strategies) {
    try {
      const compressed = await compressImage(currentDataUrl, {
        maxWidth: strategy.maxWidth,
        quality: strategy.quality
      })
      const compressedDataUrl = await blobToDataUrl(compressed)
      normalized = normalizeBase64Payload(compressedDataUrl, compressed.type)

      if (normalized.data.length <= targetLength) {
        return { ...normalized, updated: true }
      }

      currentDataUrl = normalized.dataUrl
    } catch (error) {
      console.warn('âš ï¸ åŒæ­¥åœ–ç‰‡å£“ç¸®å¤±æ•—ï¼Œæ”¹ç”¨åŽŸåœ–', error)
      return { ...normalized, updated: false }
    }
  }

  return { ...normalized, updated: true }
}

const toMillis = (value: unknown): number | undefined => {
  if (typeof value === 'number' && Number.isFinite(value)) return value
  if (typeof value === 'string' && value.trim()) {
    const parsed = Date.parse(value)
    if (Number.isFinite(parsed)) return parsed
  }
  return undefined
}

export function useSync(options: UseSyncOptions = {}) {
  const { autoSync = true } = options

  const isOnline = useOnlineStatus()
  const [status, setStatus] = useState<SyncStatus>({
    isSyncing: false,
    lastSyncTime: null,
    pendingCount: 0,
    error: null
  })
  const isSyncingRef = useRef(false)
  const syncQueuedRef = useRef(false)
  const prevOnlineRef = useRef(isOnline)
  const lastFocusSyncRef = useRef(0)
  const avoidBlobStorage = shouldAvoidIndexedDbBlob()
  const syncBlockedReasonRef = useRef<string | null>(null)
  // hasInitializedRef å·²å»¢æ£„ï¼šæ”¹ç”¨ localStorage ä¾†åˆ¤æ–·æ˜¯å¦å·²åˆå§‹åŒ–ï¼Œé¿å…é é¢åˆ·æ–°æ™‚é‡ç½®
  // const hasInitializedRef = useRef(false)

  const buildSyncUrl = useCallback(
    (extraParams?: URLSearchParams) => {
      const params = extraParams
        ? new URLSearchParams(extraParams)
        : new URLSearchParams()
      if (viewAsOwnerId) {
        params.set('ownerId', viewAsOwnerId)
      }
      const query = params.toString()
      return query ? `/api/data/sync?${query}` : '/api/data/sync'
    },
    [viewAsOwnerId]
  )

  const updateSubmissionImageCache = async (
    submissionId: string,
    blob: Blob | null,
    dataUrl: string | null
  ) => {
    const payload: Partial<Submission> = {}
    if (dataUrl) payload.imageBase64 = dataUrl
    if (!avoidBlobStorage && blob) payload.imageBlob = blob
    if (avoidBlobStorage) payload.imageBlob = undefined

    try {
      await db.submissions.update(submissionId, payload)
    } catch (error) {
      if (!avoidBlobStorage && blob && isIndexedDbBlobError(error)) {
        delete payload.imageBlob
        await db.submissions.update(submissionId, payload)
      } else {
        throw error
      }
    }
  }

  const isRlsError = (value: unknown) => {
    const message = value instanceof Error ? value.message : String(value)
    const lower = message.toLowerCase()
    return (
      lower.includes('row-level security') ||
      lower.includes('rls') ||
      lower.includes('permission denied') ||
      lower.includes('not authorized') ||
      lower.includes('not allowed')
    )
  }

  const markSyncBlocked = (reason: string) => {
    if (!syncBlockedReasonRef.current) {
      syncBlockedReasonRef.current = reason
    }
  }

  /**
   * æ›´æ–°å¾…åŒæ­¥æ•¸é‡
   */
  const updatePendingCount = useCallback(async () => {
    const count = await db.submissions
      .where('status')
      .equals('scanned')
      .count()

    setStatus((prev) => ({ ...prev, pendingCount: count }))
    return count
  }, [])

  /**
   * åŒæ­¥å–®å€‹æäº¤ç´€éŒ„
   */
  const syncSubmission = async (submission: any) => {
    try {
      debugLog(`é–‹å§‹åŒæ­¥æäº¤ ${submission.id}`)

      let imageBase64: string
      let contentType: string | undefined
      let base64DataUrl: string | null = null

      // å„ªå…ˆä½¿ç”¨ imageBase64ï¼ˆå¦‚æžœå·²ç¶“æœ‰ï¼‰
      if (submission.imageBase64) {
        debugLog('âœ… ä½¿ç”¨ç¾æœ‰çš„ Base64 æ•¸æ“š')
        const normalized = normalizeBase64Payload(
          submission.imageBase64,
          submission.imageBlob?.type
        )
        imageBase64 = normalized.data
        contentType = normalized.mimeType
        base64DataUrl = normalized.dataUrl
      } else if (submission.imageBlob) {
        // å¾ž Blob è½‰æ›
        debugLog('ðŸ”„ å¾ž Blob è½‰æ›ç‚º Base64')
        const dataUrl = await blobToDataUrl(submission.imageBlob)
        const normalized = normalizeBase64Payload(dataUrl, submission.imageBlob.type)
        imageBase64 = normalized.data
        contentType = normalized.mimeType || submission.imageBlob.type
        base64DataUrl = normalized.dataUrl
        if (avoidBlobStorage && base64DataUrl) {
          await updateSubmissionImageCache(submission.id, submission.imageBlob, base64DataUrl)
        }
      } else {
        console.warn('âš ï¸ ç¼ºå°‘åœ–ç‰‡è³‡æ–™ï¼Œå˜—è©¦å¾žé›²ç«¯ä¸‹è¼‰è£œå›ž')
        try {
          const downloaded = await downloadImageFromSupabase(submission.id)
          const dataUrl = await blobToDataUrl(downloaded)
          const normalized = normalizeBase64Payload(dataUrl, downloaded.type)
          imageBase64 = normalized.data
          contentType = normalized.mimeType || downloaded.type
          base64DataUrl = normalized.dataUrl
          await updateSubmissionImageCache(submission.id, downloaded, base64DataUrl)
        } catch (downloadError) {
          console.warn('âš ï¸ é›²ç«¯ä¸‹è¼‰å¤±æ•—ï¼Œæ¨™è¨˜ç‚ºæœªç¹³äº¤ä»¥é¿å…é‡è©¦', downloadError)
          await db.submissions.update(submission.id, { status: 'missing' })
          return true
        }
      }

      // ç¢ºå®š content type
      if (!contentType) {
        contentType = submission.imageBlob?.type || 'image/webp'
      }

      if (base64DataUrl) {
        const adjusted = await shrinkBase64Payload(
          base64DataUrl,
          contentType,
          MAX_SUBMISSION_BASE64_LENGTH
        )
        if (adjusted.updated) {
          imageBase64 = adjusted.data
          contentType = adjusted.mimeType || contentType
          base64DataUrl = adjusted.dataUrl
          await updateSubmissionImageCache(submission.id, null, base64DataUrl)
        }
      }

      const response = await fetch('/api/data/submission', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        credentials: 'include',
        body: JSON.stringify({
          submissionId: submission.id,
          assignmentId: submission.assignmentId,
          studentId: submission.studentId,
          createdAt: submission.createdAt,
          imageBase64,
          contentType
        })
      })

      let data = await response.json().catch(() => ({}))
      if (!response.ok) {
        if (response.status === 413 && base64DataUrl) {
          console.warn('âš ï¸ åŒæ­¥æª”æ¡ˆéŽå¤§ï¼Œå˜—è©¦æ›´é«˜å£“ç¸®å¾Œé‡è©¦')
          const adjusted = await shrinkBase64Payload(
            base64DataUrl,
            contentType,
            HARD_MAX_SUBMISSION_BASE64_LENGTH
          )
          if (adjusted.updated) {
            imageBase64 = adjusted.data
            contentType = adjusted.mimeType || contentType
            base64DataUrl = adjusted.dataUrl
            await updateSubmissionImageCache(submission.id, null, base64DataUrl)
          }

          const retryResponse = await fetch('/api/data/submission', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            credentials: 'include',
            body: JSON.stringify({
              submissionId: submission.id,
              assignmentId: submission.assignmentId,
              studentId: submission.studentId,
              createdAt: submission.createdAt,
              imageBase64,
              contentType
            })
          })

          data = await retryResponse.json().catch(() => ({}))
          if (!retryResponse.ok) {
            const message = data?.error || 'åŒæ­¥å¤±æ•—'
            if (isRlsError(message) || retryResponse.status === 401 || retryResponse.status === 403) {
              console.warn('âš ï¸ åŒæ­¥é­åˆ°æ¬Šé™é™åˆ¶ (RLS)ï¼Œæš«åœåŒæ­¥:', message)
              markSyncBlocked(message)
              return false
            }
            throw new Error(message)
          }
        } else {
          const message = data?.error || 'åŒæ­¥å¤±æ•—'
          if (isRlsError(message) || response.status === 401 || response.status === 403) {
            console.warn('âš ï¸ åŒæ­¥é­åˆ°æ¬Šé™é™åˆ¶ (RLS)ï¼Œæš«åœåŒæ­¥:', message)
            markSyncBlocked(message)
            return false
          }
          throw new Error(message)
        }
      }

      debugLog('åœ–ç‰‡èˆ‡è³‡æ–™åŒæ­¥æˆåŠŸ')

      // åŒæ­¥æˆåŠŸå¾Œï¼Œæ›´æ–°ç‹€æ…‹ä½†ä¿ç•™æœ¬åœ°åœ–ç‰‡æ•¸æ“š
      debugLog('ðŸ“ æ›´æ–°æœ¬åœ°ç‹€æ…‹ç‚º syncedï¼Œä¿ç•™åœ–ç‰‡æ•¸æ“š...')

      // å…ˆæª¢æŸ¥ç•¶å‰æ•¸æ“š
      const beforeUpdate = await db.submissions.get(submission.id)
      debugLog('æ›´æ–°å‰:', {
        hasBlob: !!beforeUpdate?.imageBlob,
        blobSize: beforeUpdate?.imageBlob?.size,
        hasBase64: !!beforeUpdate?.imageBase64,
        base64Length: beforeUpdate?.imageBase64?.length
      })

      const newImageUrl = `submissions/${submission.id}.webp`
      console.log('ðŸ”„ [åŒæ­¥] æ›´æ–°æœ¬åœ° submission ç‹€æ…‹:', {
        submissionId: submission.id,
        oldImageUrl: beforeUpdate?.imageUrl,
        newImageUrl,
        oldStatus: beforeUpdate?.status,
        newStatus: 'synced'
      })

      await db.submissions.update(submission.id, {
        status: 'synced',
        imageUrl: newImageUrl
        // æ³¨æ„ï¼šä¸æ›´æ–° imageBlob å’Œ imageBase64ï¼Œä¿ç•™åŽŸæœ‰æ•¸æ“š
      })

      // é©—è­‰æ›´æ–°å¾Œæ•¸æ“š
      const afterUpdate = await db.submissions.get(submission.id)
      debugLog('æ›´æ–°å¾Œ:', {
        status: afterUpdate?.status,
        hasBlob: !!afterUpdate?.imageBlob,
        blobSize: afterUpdate?.imageBlob?.size,
        hasBase64: !!afterUpdate?.imageBase64,
        base64Length: afterUpdate?.imageBase64?.length,
        imageUrl: afterUpdate?.imageUrl
      })

      console.log('âœ… [åŒæ­¥] æœ¬åœ° submission æ›´æ–°å®Œæˆ:', {
        submissionId: submission.id,
        imageUrl: afterUpdate?.imageUrl,
        status: afterUpdate?.status
      })

      if (beforeUpdate?.imageBlob && !afterUpdate?.imageBlob) {
        console.error('âš ï¸ è­¦å‘Šï¼šæ›´æ–°å¾Œ Blob ä¸Ÿå¤±ï¼')
      }
      if (beforeUpdate?.imageBase64 && !afterUpdate?.imageBase64) {
        console.error('âš ï¸ è­¦å‘Šï¼šæ›´æ–°å¾Œ Base64 ä¸Ÿå¤±ï¼')
      }

      debugLog('âœ… æœ¬åœ°ç‹€æ…‹æ›´æ–°æˆåŠŸ')

      return true
    } catch (error) {
      if (isRlsError(error)) {
        console.warn('âš ï¸ åŒæ­¥é­åˆ°æ¬Šé™é™åˆ¶ (RLS)ï¼Œæš«åœåŒæ­¥:', error)
        markSyncBlocked(error instanceof Error ? error.message : String(error))
        return false
      }
      console.error(`åŒæ­¥å¤±æ•— ${submission.id}:`, error)
      throw error
    }
  }

  /**
   * ä¸Šå‚³æœ¬æ©Ÿè³‡æ–™åˆ°é›²ç«¯
   */
  const pushMetadata = useCallback(async () => {
    debugLog('ðŸ“¤ pushMetadata é–‹å§‹')
    const [classrooms, students, assignments, submissions, folders, deleteQueue] =
      await Promise.all([
        db.classrooms.toArray(),
        db.students.toArray(),
        db.assignments.toArray(),
        db.submissions.toArray(),
        db.folders.toArray(),
        readDeleteQueue()
      ])

    console.log('ðŸ”„ [åŒæ­¥] è®€å–åˆªé™¤ä½‡åˆ—:', {
      count: deleteQueue.length,
      items: deleteQueue.map(q => ({ tableName: q.tableName, recordId: q.recordId }))
    })

    debugLog('ðŸ“Š pushMetadata è®€å–çš„ folders:', folders)

    const deleteQueueIds = deleteQueue
      .map((item) => item.id)
      .filter((id): id is number => typeof id === 'number')

    const deletedPayload: Record<string, Array<{ id: string; deletedAt: number }>> = {
      classrooms: [],
      students: [],
      assignments: [],
      submissions: [],
      folders: []
    }

    const deleteMap = new Map<
      string,
      { tableName: string; recordId: string; deletedAt: number }
    >()

    for (const entry of deleteQueue) {
      if (!entry.tableName || !entry.recordId) continue
      const key = `${entry.tableName}:${entry.recordId}`
      const existing = deleteMap.get(key)
      if (!existing || entry.deletedAt > existing.deletedAt) {
        deleteMap.set(key, {
          tableName: entry.tableName,
          recordId: entry.recordId,
          deletedAt: entry.deletedAt
        })
      }
    }

    for (const entry of deleteMap.values()) {
      const bucket = deletedPayload[entry.tableName]
      if (bucket) {
        bucket.push({ id: entry.recordId, deletedAt: entry.deletedAt })
      }
    }

    console.log('ðŸ“¦ [åŒæ­¥] æº–å‚™ç™¼é€åˆªé™¤è³‡æ–™:', {
      submissions: deletedPayload.submissions.length,
      total: Object.values(deletedPayload).reduce((sum, arr) => sum + arr.length, 0),
      deletedPayload
    })

    const classroomPayload = classrooms
      .filter((c) => c?.id)
      .map((c) => ({
        id: c.id,
        name: c.name,
        folder: c.folder === undefined ? null : c.folder,
        updatedAt: c.updatedAt
      }))

    debugLog('ðŸ“¤ pushMetadata - æº–å‚™ç™¼é€çš„ classrooms:', classroomPayload)

    const studentPayload = students
      .filter((s) => s?.id && s?.classroomId)
      .map((s) => ({
        id: s.id,
        classroomId: s.classroomId,
        seatNumber: s.seatNumber,
        name: s.name,
        updatedAt: s.updatedAt
      }))

    const assignmentPayload = assignments
      .filter((a) => a?.id && a?.classroomId)
      .map((a) => ({
        id: a.id,
        classroomId: a.classroomId,
        title: a.title,
        totalPages: a.totalPages,
        domain: a.domain,
        folder: a.folder === undefined ? null : a.folder,
        priorWeightTypes: a.priorWeightTypes,
        answerKey: a.answerKey,
        updatedAt: a.updatedAt
      }))
    
    console.log(`ðŸ“¤ [Sync Push] æº–å‚™ä¸Šå‚³ ${assignmentPayload.length} å€‹ä½œæ¥­:`, assignmentPayload.map(a => ({ id: a.id, title: a.title, hasAnswerKey: !!a.answerKey })))

    const submissionPayload = submissions
      .filter((sub) => sub.status !== 'scanned')
      .map(({ imageBlob, ...rest }) => ({
        id: rest.id,
        assignmentId: rest.assignmentId,
        studentId: rest.studentId,
        status: rest.status,
        createdAt: rest.createdAt,
        imageUrl: rest.imageUrl || `submissions/${rest.id}.webp`,
        score: rest.score,
        feedback: rest.feedback,
        gradingResult: rest.gradingResult,
        gradedAt: rest.gradedAt,
        correctionCount: rest.correctionCount,
        updatedAt: rest.updatedAt
      }))

    const foldersPayload = folders
      .filter((f) => f?.id && f?.name)
      .map((f) => ({
        id: f.id,
        name: f.name,
        type: f.type,
        updatedAt: f.updatedAt
      }))

    const response = await fetch(buildSyncUrl(), {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      credentials: 'include',
      body: JSON.stringify({
        classrooms: classroomPayload,
        students: studentPayload,
        assignments: assignmentPayload,
        submissions: submissionPayload,
        folders: foldersPayload,
        deleted: deletedPayload
      })
    })

    const data = await response.json().catch(() => ({}))
    if (!response.ok) {
      const message = data?.error || 'åŒæ­¥å¤±æ•—'
      if (isRlsError(message) || response.status === 401 || response.status === 403) {
        console.warn('âš ï¸ pushMetadata é­åˆ°æ¬Šé™é™åˆ¶ (RLS)ï¼Œæš«åœåŒæ­¥:', message)
        markSyncBlocked(message)
        return
      }
      throw new Error(message)
    }

    debugLog('âœ… pushMetadata å®Œæˆ')

    // pushMetadata å¾Œå†æª¢æŸ¥ä¸€æ¬¡ folders
    const afterPush = await db.folders.toArray()
    debugLog('ðŸ“Š pushMetadata å¾Œæœ¬åœ° folders:', afterPush)

    if (deleteQueueIds.length > 0) {
      await clearDeleteQueue(deleteQueueIds)
    }
  }, [buildSyncUrl])

  /**
   * å¾žé›²ç«¯æ‹‰å›žè³‡æ–™
   */
  const pullMetadata = useCallback(async () => {
    debugLog('ðŸ“¥ pullMetadata é–‹å§‹')
    const response = await fetch(buildSyncUrl(), {
      method: 'GET',
      credentials: 'include'
    })

    const data = await response.json().catch(() => ({}))
    if (!response.ok) {
      const message = data?.error || 'è¼‰å…¥é›²ç«¯è³‡æ–™å¤±æ•—'
      if (isRlsError(message) || response.status === 401 || response.status === 403) {
        console.warn('âš ï¸ pullMetadata é­åˆ°æ¬Šé™é™åˆ¶ (RLS)ï¼Œæš«åœåŒæ­¥:', message)
        markSyncBlocked(message)
        return
      }
      throw new Error(message)
    }

    const classrooms = Array.isArray(data.classrooms) ? data.classrooms : []
    const students = Array.isArray(data.students) ? data.students : []
    const assignments = Array.isArray(data.assignments) ? data.assignments : []
    const submissions = Array.isArray(data.submissions) ? data.submissions : []
    const folders = Array.isArray(data.folders) ? data.folders : []
    const deleted = data?.deleted && typeof data.deleted === 'object' ? data.deleted : {}
    
    console.log(`ðŸ“¥ [Sync Pull] å¾žé›²ç«¯æ‹‰å– ${assignments.length} å€‹ä½œæ¥­:`, assignments.map((a: any) => ({ id: a.id, title: a.title, hasAnswerKey: !!a.answerKey })))

    const collectDeletedIds = (items: unknown) =>
      Array.isArray(items)
        ? items
            .map((item) => {
              if (typeof item === 'string') return item
              if (item && typeof item === 'object' && 'id' in item) {
                return (item as { id?: unknown }).id
              }
              return null
            })
            .filter((id): id is string => typeof id === 'string' && id.length > 0)
        : []

    const deletedClassroomIds = collectDeletedIds(deleted.classrooms)
    const deletedStudentIds = collectDeletedIds(deleted.students)
    const deletedAssignmentIds = collectDeletedIds(deleted.assignments)
    const deletedSubmissionIds = collectDeletedIds(deleted.submissions)
    const deletedFolderIds = collectDeletedIds(deleted.folders)

    debugLog('ðŸ—‘ï¸ è¦åˆªé™¤çš„ folders:', deletedFolderIds)

    // åœ¨ bulkDelete ä¹‹å‰æª¢æŸ¥ folders
    const beforeDelete = await db.folders.toArray()
    debugLog('ðŸ“Š bulkDelete ä¹‹å‰çš„ folders:', beforeDelete)

    const deletedClassroomSet = new Set(deletedClassroomIds)
    const deletedStudentSet = new Set(deletedStudentIds)
    const deletedAssignmentSet = new Set(deletedAssignmentIds)
    const deletedSubmissionSet = new Set(deletedSubmissionIds)
    const deletedFolderSet = new Set(deletedFolderIds)

    const existingSubmissions = await db.submissions.toArray()

    debugLog(`ðŸ“¦ pullMetadata: å¾žé›²ç«¯æ‹‰å– ${submissions.length} ç­† submissions`)
    debugLog(`ðŸ“¦ pullMetadata: æœ¬åœ°ç¾æœ‰ ${existingSubmissions.length} ç­† submissions`)

    // ä¿ç•™æœ¬åœ°åœ–ç‰‡æ•¸æ“šï¼ˆBlob å’Œ Base64ï¼‰
    const imageDataMap = new Map(
      existingSubmissions.map((sub) => [
        sub.id,
        {
          imageBlob: sub.imageBlob,
          imageBase64: sub.imageBase64
        }
      ])
    )

    debugLog(`ðŸ“¦ imageDataMap å»ºç«‹å®Œæˆï¼ŒåŒ…å« ${imageDataMap.size} ç­†åœ–ç‰‡æ•¸æ“š`)

    // çµ±è¨ˆæœ‰å¤šå°‘æœ¬åœ°åœ–ç‰‡æ•¸æ“š
    let blobCount = 0
    let base64Count = 0
    imageDataMap.forEach((data) => {
      if (data.imageBlob) blobCount++
      if (data.imageBase64) base64Count++
    })
    debugLog(`ðŸ“Š æœ¬åœ°åœ–ç‰‡çµ±è¨ˆ: ${blobCount} å€‹ Blob, ${base64Count} å€‹ Base64`)

    const mergedSubmissions: Submission[] = submissions
      .filter(
        (sub: Submission) =>
          sub?.id &&
          sub?.assignmentId &&
          sub?.studentId &&
          !deletedSubmissionSet.has(sub.id)
      )
      .map((sub: Submission) => {
        const createdAt =
          typeof sub.createdAt === 'number' && Number.isFinite(sub.createdAt)
            ? sub.createdAt
            : Date.now()
        const gradedAt =
          typeof sub.gradedAt === 'number' && Number.isFinite(sub.gradedAt)
            ? sub.gradedAt
            : undefined

        // å¾žæœ¬åœ°æ¢å¾©åœ–ç‰‡æ•¸æ“š
        const localImageData = imageDataMap.get(sub.id)

        if (localImageData && (localImageData.imageBlob || localImageData.imageBase64)) {
          debugLog(`ðŸ”„ æ¢å¾©åœ–ç‰‡æ•¸æ“š: ${sub.id}`, {
            hasBlob: !!localImageData.imageBlob,
            hasBase64: !!localImageData.imageBase64,
            base64Length: localImageData.imageBase64?.length
          })
        }

        return {
          id: sub.id,
          assignmentId: sub.assignmentId,
          studentId: sub.studentId,
          status: sub.status || 'synced',
          createdAt,
          score: sub.score,
          feedback: sub.feedback,
          gradingResult: sub.gradingResult,
          gradedAt,
          correctionCount: sub.correctionCount,
          imageUrl: sub.imageUrl,
          imageBlob: localImageData?.imageBlob,       // ä¿ç•™æœ¬åœ° Blob
          imageBase64: localImageData?.imageBase64,   // ä¿ç•™æœ¬åœ° Base64
          updatedAt: toMillis(sub.updatedAt ?? (sub as { updated_at?: unknown }).updated_at)
        }
      })

    debugLog(`âœ… åˆä½µå®Œæˆï¼Œæº–å‚™å¯«å…¥ ${mergedSubmissions.length} ç­† submissions`)

    // çµ±è¨ˆåˆä½µå¾Œçš„åœ–ç‰‡æ•¸æ“š
    let mergedBlobCount = 0
    let mergedBase64Count = 0
    mergedSubmissions.forEach((sub) => {
      if (sub.imageBlob) mergedBlobCount++
      if (sub.imageBase64) mergedBase64Count++
    })
    debugLog(`ðŸ“Š åˆä½µå¾Œåœ–ç‰‡çµ±è¨ˆ: ${mergedBlobCount} å€‹ Blob, ${mergedBase64Count} å€‹ Base64`)

    debugLog('ðŸ“¥ pullMetadata - å¾žé›²ç«¯æ”¶åˆ°çš„åŽŸå§‹ classrooms:', classrooms)

    // ä¿ç•™æœ¬åœ°çš„ folder è³‡æ–™ï¼ˆå› ç‚ºå¾Œç«¯å¯èƒ½é‚„ä¸æ”¯æ´ folder æ¬„ä½ï¼‰
    const existingClassrooms = await db.classrooms.toArray()
    const localFolderMap = new Map(
      existingClassrooms.map((c) => [c.id, c.folder])
    )

    const normalizedClassrooms: Classroom[] = classrooms
      .filter((c: Classroom) => c?.id && !deletedClassroomSet.has(c.id))
      .map((c: Classroom) => {
        const cloudFolder = (c as Classroom & { folder?: string }).folder
        const localFolder = localFolderMap.get(c.id)

        // å¦‚æžœé›²ç«¯æœ‰ folderï¼Œä½¿ç”¨é›²ç«¯çš„ï¼›å¦å‰‡ä¿ç•™æœ¬åœ°çš„
        const finalFolder = cloudFolder !== undefined ? cloudFolder : localFolder

        return {
          id: c.id,
          name: c.name,
          folder: finalFolder,
          updatedAt: toMillis(
            (c as Classroom & { updatedAt?: unknown }).updatedAt ??
              (c as { updated_at?: unknown }).updated_at
          )
        }
      })

    debugLog('ðŸ“¥ pullMetadata - æ­£è¦åŒ–å¾Œçš„ classrooms:', normalizedClassrooms)

    const normalizedStudents: Student[] = students
      .filter((s: Student) => s?.id && s?.classroomId && !deletedStudentSet.has(s.id))
      .map((s: Student) => ({
        id: s.id,
        classroomId: s.classroomId,
        seatNumber: s.seatNumber,
        name: s.name,
        updatedAt: toMillis(
          (s as Student & { updatedAt?: unknown }).updatedAt ??
            (s as { updated_at?: unknown }).updated_at
        )
      }))

    // ä¿ç•™æœ¬åœ°çš„ assignment folder è³‡æ–™ï¼ˆå› ç‚ºå¾Œç«¯å¯èƒ½é‚„ä¸æ”¯æ´ folder æ¬„ä½ï¼‰
    const existingAssignments = await db.assignments.toArray()
    const localAssignmentFolderMap = new Map(
      existingAssignments.map((a) => [a.id, { folder: a.folder, priorWeightTypes: a.priorWeightTypes }])
    )

    const normalizedAssignments: Assignment[] = assignments
      .filter(
        (a: Assignment) => a?.id && a?.classroomId && !deletedAssignmentSet.has(a.id)
      )
      .map((a: Assignment) => {
        const cloudFolder = (a as Assignment & { folder?: string }).folder
        const cloudPriorWeightTypes = (a as Assignment & { priorWeightTypes?: any }).priorWeightTypes
        const localData = localAssignmentFolderMap.get(a.id)

        // å¦‚æžœé›²ç«¯æœ‰è³‡æ–™ï¼Œä½¿ç”¨é›²ç«¯çš„ï¼›å¦å‰‡ä¿ç•™æœ¬åœ°çš„
        const finalFolder = cloudFolder !== undefined ? cloudFolder : localData?.folder
        const finalPriorWeightTypes = cloudPriorWeightTypes !== undefined ? cloudPriorWeightTypes : localData?.priorWeightTypes

        return {
          id: a.id,
          classroomId: a.classroomId,
          title: a.title,
          totalPages: a.totalPages,
          domain: a.domain ?? undefined,
          folder: finalFolder,
          priorWeightTypes: finalPriorWeightTypes,
          answerKey: a.answerKey ?? undefined,
          updatedAt: toMillis(
            (a as Assignment & { updatedAt?: unknown }).updatedAt ??
              (a as { updated_at?: unknown }).updated_at
          )
        }
      })

    const normalizedFolders = folders
      .filter((f: any) => f?.id && f?.name && !deletedFolderSet.has(f.id))
      .map((f: any) => ({
        id: f.id,
        name: f.name,
        type: f.type,
        updatedAt: toMillis(
          (f as { updatedAt?: unknown }).updatedAt ??
            (f as { updated_at?: unknown }).updated_at
        )
      }))

    if (deletedClassroomIds.length > 0) {
      await db.classrooms.bulkDelete(deletedClassroomIds)
    }
    if (deletedStudentIds.length > 0) {
      await db.students.bulkDelete(deletedStudentIds)
    }
    if (deletedAssignmentIds.length > 0) {
      await db.assignments.bulkDelete(deletedAssignmentIds)
    }
    if (deletedSubmissionIds.length > 0) {
      await db.submissions.bulkDelete(deletedSubmissionIds)
    }
    if (deletedFolderIds.length > 0) {
      debugLog('âš ï¸ åŸ·è¡Œåˆªé™¤ folders:', deletedFolderIds)
      await db.folders.bulkDelete(deletedFolderIds)
    }

    // åœ¨æ‰€æœ‰ bulkDelete ä¹‹å¾Œæª¢æŸ¥ folders
    const afterDelete = await db.folders.toArray()
    debugLog('ðŸ“Š bulkDelete ä¹‹å¾Œçš„ folders:', afterDelete)

    // å…ˆæª¢æŸ¥ folders ç‹€æ…‹
    const beforePut = await db.folders.toArray()
    debugLog('ðŸ“Š bulkPut ä¹‹å‰çš„ folders:', beforePut)

    await db.classrooms.bulkPut(normalizedClassrooms)

    // æª¢æŸ¥å¯«å…¥å¾Œçš„ classrooms
    const afterPutClassrooms = await db.classrooms.toArray()
    debugLog('ðŸ“Š bulkPut classrooms ä¹‹å¾Œçš„è³‡æ–™:', afterPutClassrooms)

    await db.students.bulkPut(normalizedStudents)
    await db.assignments.bulkPut(normalizedAssignments)
    await db.submissions.bulkPut(mergedSubmissions)

    // å†æª¢æŸ¥ folders ç‹€æ…‹
    const afterPut = await db.folders.toArray()
    debugLog('ðŸ“Š bulkPut ä¹‹å¾Œçš„ folders:', afterPut)

    // åªæœ‰ç•¶é›²ç«¯æœ‰ folders è³‡æ–™æ™‚æ‰æ›´æ–°ï¼ˆé¿å…è¦†è“‹æœ¬åœ°è³‡æ–™ï¼‰
    if (folders.length > 0) {
      await db.folders.bulkPut(normalizedFolders)
      debugLog(`âœ… åŒæ­¥äº† ${normalizedFolders.length} å€‹è³‡æ–™å¤¾`)
    } else {
      debugLog('âš ï¸ é›²ç«¯æ²’æœ‰ folders è³‡æ–™ï¼Œä¿ç•™æœ¬åœ°è³‡æ–™å¤¾')

      // é©—è­‰æœ¬åœ°è³‡æ–™å¤¾æ˜¯å¦çœŸçš„ä¿ç•™
      const localFolders = await db.folders.toArray()
      debugLog('ðŸ” pullMetadata å¾Œæœ¬åœ° folders:', localFolders)
    }
  }, [buildSyncUrl])

  // ä½¿ç”¨ localStorage è¿½è¹¤æœ¬åœ°è³‡æ–™å°æ‡‰çš„ ownerId
  const SYNC_OWNER_KEY = 'sync_current_owner_id'

  useEffect(() => {
    // å–å¾—æœ¬åœ°è³‡æ–™ç›®å‰å°æ‡‰çš„ ownerId
    const storedOwnerId = localStorage.getItem(SYNC_OWNER_KEY)
    const currentOwnerId = viewAsOwnerId ?? '__self__'

    console.log('ðŸ” [useSync] æª¢æŸ¥æ˜¯å¦éœ€è¦ resetLocal:', {
      storedOwnerId,
      currentOwnerId,
      isMatch: storedOwnerId === currentOwnerId,
      isOnline
    })

    // âœ… ä¿®å¾©ï¼šåªè¦ localStorage ä¸­çš„ ownerId åŒ¹é…ï¼Œå°±èªç‚ºå·²åˆå§‹åŒ–
    // ä¸å†ä¾è³´ hasInitializedRefï¼Œå› ç‚ºå®ƒåœ¨é é¢åˆ·æ–°æ™‚æœƒä¸Ÿå¤±
    if (storedOwnerId === currentOwnerId) {
      console.log('âœ… [useSync] ownerId åŒ¹é…ï¼Œè·³éŽ resetLocal')
      viewAsRef.current = viewAsOwnerId

      // é é¢åˆ·æ–°å¾Œï¼ŒåŸ·è¡Œä¸€æ¬¡æ­£å¸¸åŒæ­¥
      // æ³¨æ„ï¼šä¸åœ¨æ­¤è™•ç›´æŽ¥èª¿ç”¨ performSyncï¼Œè®“å…¶ä»– useEffect è‡ªå‹•è§¸ç™¼åŒæ­¥
      if (isOnline) {
        void updatePendingCount()
      }
      return  // è·³éŽ resetLocal
    }

    // åªæœ‰åœ¨æ˜Žç¢ºåˆ‡æ›ç”¨æˆ¶æ™‚æ‰æ¸…ç©ºæ•¸æ“š
    console.log('âš ï¸ [useSync] ownerId ä¸åŒ¹é…ï¼Œéœ€è¦æ¸…ç©ºä¸¦é‡æ–°è¼‰å…¥', {
      from: storedOwnerId,
      to: currentOwnerId
    })

    viewAsRef.current = viewAsOwnerId
    syncBlockedReasonRef.current = null

    const resetLocal = async () => {
      console.log('ðŸ”„ [useSync] ViewAs è®Šæ›´ï¼Œé‡æ–°è¼‰å…¥è³‡æ–™...', { from: storedOwnerId, to: currentOwnerId })
      isSyncingRef.current = false
      syncQueuedRef.current = false
      await Promise.all([
        db.classrooms.clear(),
        db.students.clear(),
        db.assignments.clear(),
        db.submissions.clear(),
        db.syncQueue.clear(),
        db.folders.clear(),
        db.answerExtractionCorrections.clear()
      ])

      // å„²å­˜ç•¶å‰çš„ ownerId
      localStorage.setItem(SYNC_OWNER_KEY, currentOwnerId)

      setStatus((prev) => ({
        ...prev,
        lastSyncTime: null,
        pendingCount: 0,
        error: null
      }))

      if (!isOnline) return

      await pullMetadata()
      if (!syncBlockedReasonRef.current) {
        const remainingCount = await updatePendingCount()
        setStatus((prev) => ({
          ...prev,
          lastSyncTime: Date.now(),
          pendingCount: remainingCount,
          error: null
        }))
      }
    }

    void resetLocal()
  }, [viewAsOwnerId, isOnline, pullMetadata, updatePendingCount])

  /**
   * åŸ·è¡ŒåŒæ­¥
   */
  const performSync = useCallback(async () => {
    if (!isOnline) {
      console.log('ðŸ“¡ [åŒæ­¥] è·³éŽåŒæ­¥ï¼šé›¢ç·šç‹€æ…‹')
      debugLog('é›¢ç·šç‹€æ…‹ï¼Œè·³éŽåŒæ­¥')
      void updatePendingCount()
      notifySyncComplete() // é€šçŸ¥ç­‰å¾…è€…åŒæ­¥å·²çµæŸï¼ˆå³ä½¿è·³éŽï¼‰
      return
    }

    if (isSyncingRef.current) {
      console.log('ðŸ”„ [åŒæ­¥] è·³éŽåŒæ­¥ï¼šç›®å‰æ­£åœ¨åŒæ­¥ä¸­ï¼Œå·²åŠ å…¥ä½‡åˆ—')
      debugLog('ç›®å‰æ­£åœ¨åŒæ­¥ä¸­ï¼Œè·³éŽæœ¬æ¬¡')
      syncQueuedRef.current = true
      // ä¸è§¸ç™¼ notifySyncCompleteï¼Œå› ç‚ºé€²è¡Œä¸­çš„åŒæ­¥æœƒè§¸ç™¼
      return
    }

    if (syncBlockedReasonRef.current) {
      console.log('ðŸš« [åŒæ­¥] è·³éŽåŒæ­¥ï¼šRLS æ¬Šé™é™åˆ¶ -', syncBlockedReasonRef.current)
      console.warn('âš ï¸ å·²åµæ¸¬åˆ° RLS æ¬Šé™é™åˆ¶ï¼Œæš«åœåŒæ­¥:', syncBlockedReasonRef.current)
      setStatus((prev) => ({ ...prev, isSyncing: false, error: null }))
      notifySyncComplete() // é€šçŸ¥ç­‰å¾…è€…åŒæ­¥å·²çµæŸï¼ˆå³ä½¿è¢«é˜»æ“‹ï¼‰
      return
    }

    try {
      isSyncingRef.current = true
      setStatus((prev) => ({ ...prev, isSyncing: true, error: null }))

      // æª¢æŸ¥ performSync é–‹å§‹æ™‚çš„ folders
      const performSyncStart = await db.folders.toArray()
      debugLog('ðŸ”µ performSync é–‹å§‹æ™‚çš„ folders:', performSyncStart)

      const pendingSubmissions = await db.submissions
        .where('status')
        .equals('scanned')
        .toArray()

      console.log('ðŸ”„ [åŒæ­¥] æº–å‚™ä¸Šå‚³ submissions:', {
        count: pendingSubmissions.length,
        ids: pendingSubmissions.map(s => s.id)
      })

      debugLog(`æ‰¾åˆ° ${pendingSubmissions.length} æ¢å¾…åŒæ­¥ç´€éŒ„`)

      let successCount = 0
      let failCount = 0

      for (const submission of pendingSubmissions) {
        try {
          const result = await syncSubmission(submission)
          if (result) {
            successCount++
          }
        } catch (error) {
          failCount++
          console.error('åŒæ­¥å¤±æ•—:', error)
        }
      }

      if (pendingSubmissions.length > 0) {
        infoLog(`åŒæ­¥å®Œæˆï¼šæˆåŠŸ ${successCount} ç­†ï¼Œå¤±æ•— ${failCount} ç­†`)
      }

      // æª¢æŸ¥ push å‰çš„ folders
      if (syncBlockedReasonRef.current) {
        setStatus((prev) => ({
          ...prev,
          isSyncing: false,
          error: null
        }))
        return
      }

      const beforePush = await db.folders.toArray()
      debugLog('ðŸ”µ pushMetadata å‰çš„ folders:', beforePush)

      await pushMetadata()
      if (syncBlockedReasonRef.current) {
        setStatus((prev) => ({
          ...prev,
          isSyncing: false,
          error: null
        }))
        return
      }

      // æª¢æŸ¥ push å¾Œã€pull å‰çš„ folders
      const afterPushBeforePull = await db.folders.toArray()
      debugLog('ðŸ”µ pushMetadata å¾Œã€pullMetadata å‰çš„ folders:', afterPushBeforePull)

      await pullMetadata()
      if (syncBlockedReasonRef.current) {
        setStatus((prev) => ({
          ...prev,
          isSyncing: false,
          error: null
        }))
        return
      }

      const remainingCount = await updatePendingCount()

      setStatus((prev) => ({
        ...prev,
        isSyncing: false,
        lastSyncTime: Date.now(),
        pendingCount: remainingCount,
        error: syncBlockedReasonRef.current
          ? null
          : failCount > 0
            ? `${failCount} æ¢è¨˜éŒ„åŒæ­¥å¤±æ•—`
            : null
      }))

      // é€šçŸ¥åŒæ­¥å®Œæˆ
      notifySyncComplete()
    } catch (error) {
      if (isRlsError(error)) {
        markSyncBlocked(error instanceof Error ? error.message : String(error))
        setStatus((prev) => ({ ...prev, isSyncing: false, error: null }))
        return
      }
      console.error('åŒæ­¥éŽç¨‹ç™¼ç”ŸéŒ¯èª¤:', error)
      setStatus((prev) => ({
        ...prev,
        isSyncing: false,
        error: error instanceof Error ? error.message : 'åŒæ­¥å¤±æ•—'
      }))
    } finally {
      isSyncingRef.current = false
      if (syncQueuedRef.current) {
        syncQueuedRef.current = false
        window.setTimeout(() => {
          void performSync()
        }, 0)
      }
    }
  }, [isOnline, isReadOnly, updatePendingCount, pushMetadata, pullMetadata])

  /**
   * æä¾›çµ¦å¤–éƒ¨æ‰‹å‹•è§¸ç™¼åŒæ­¥
   */
  const triggerSync = useCallback(() => {
    debugLog('æ‰‹å‹•è§¸ç™¼åŒæ­¥')
    void performSync()
  }, [performSync])

  useEffect(() => {
    if (!autoSync) return

    void updatePendingCount()
    if (isOnline) {
      void performSync()
    }
  }, [autoSync, isOnline, performSync, updatePendingCount])

  useEffect(() => {
    if (!autoSync) return
    const wasOnline = prevOnlineRef.current
    prevOnlineRef.current = isOnline
    if (!wasOnline && isOnline) {
      debugLog('ç¶²è·¯æ¢å¾©ï¼Œè§¸ç™¼åŒæ­¥')
      void performSync()
    }
  }, [isOnline, autoSync, performSync])

  useEffect(() => {
    if (!autoSync) return

    const triggerIfVisible = () => {
      if (document.visibilityState !== 'visible') return
      const now = Date.now()
      if (now - lastFocusSyncRef.current < 500) return
      lastFocusSyncRef.current = now
      void performSync()
    }

    const handleVisibility = () => {
      triggerIfVisible()
    }

    const handleFocus = () => {
      triggerIfVisible()
    }

    document.addEventListener('visibilitychange', handleVisibility)
    window.addEventListener('focus', handleFocus)
    return () => {
      document.removeEventListener('visibilitychange', handleVisibility)
      window.removeEventListener('focus', handleFocus)
    }
  }, [autoSync, performSync])

  useEffect(() => {
    if (!autoSync) return

    const handleSyncRequest = () => {
      void performSync()
    }

    window.addEventListener(SYNC_EVENT_NAME, handleSyncRequest)
    return () => {
      window.removeEventListener(SYNC_EVENT_NAME, handleSyncRequest)
    }
  }, [autoSync, performSync])

  return {
    ...status,
    triggerSync,
    updatePendingCount
  }
}






